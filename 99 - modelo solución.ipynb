{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "YA QUE AL USAR HIPERPARAMETROS EL C√ìDIGO LE ECIGI√ì MUCHO AL ENTORNO DE GOOGLE COLAB SE OPT√ì POR ADECUARLO Y CORRERLO EN UN ENTORNO LOCAL CON MAS CAPACIDAD Y EL C√ìDIGO ES EL SIGUEINTE:"
      ],
      "metadata": {
        "id": "9jaJTcOeGhXw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApsiI5_bD8fU"
      },
      "outputs": [],
      "source": [
        "# =============================================================\n",
        "# ESTA SOLUCI√ìN ES PARA EJECUTARSE EN LOCAL, EN EL PC PERSONAL O\n",
        "# EN UN EDITOR COMO SPYDER.\n",
        "# =============================================================\n",
        "# IMPORTAR LIBRER√çAS\n",
        "# =============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from unidecode import unidecode\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# =============================================================\n",
        "# CARGAR ARCHIVOS\n",
        "# =============================================================\n",
        "\n",
        "# Ruta base (Debe cambiar este enlace por la ruta en donde tiene guardado los documentos en su computador personal)\n",
        "ruta_base = 'C:\\\\Users\\\\fesal\\\\Downloads\\\\udea-ai-4-eng-20251-pruebas-saber-pro-colombia (1)\\\\'\n",
        "\n",
        "df_train = pd.read_csv(ruta_base + 'train.csv', engine='python', on_bad_lines='skip')\n",
        "df_test = pd.read_csv(ruta_base + 'test.csv', engine='python', on_bad_lines='skip')\n",
        "submission_example = pd.read_csv(ruta_base + 'submission_example.csv')\n",
        "\n",
        "# =============================================================\n",
        "# LIMPIEZA Y PROCESAMIENTO DE DATOS\n",
        "# =============================================================\n",
        "\n",
        "# Eliminar columna no √∫til si existe\n",
        "for df in [df_train, df_test]:\n",
        "    if \"ESTU_PRIVADO_LIBERTAD\" in df.columns:\n",
        "        del df[\"ESTU_PRIVADO_LIBERTAD\"]\n",
        "\n",
        "columns_to_convert = [\n",
        "    'ESTU_PRGM_ACADEMICO','ESTU_PRGM_DEPARTAMENTO', 'ESTU_VALORMATRICULAUNIVERSIDAD',\n",
        "    'ESTU_HORASSEMANATRABAJA', 'FAMI_ESTRATOVIVIENDA', 'FAMI_TIENEINTERNET',\n",
        "    'FAMI_EDUCACIONPADRE', 'FAMI_TIENELAVADORA', 'FAMI_TIENEAUTOMOVIL',\n",
        "    'ESTU_PAGOMATRICULAPROPIO', 'FAMI_TIENECOMPUTADOR',\n",
        "    'FAMI_TIENEINTERNET.1', 'FAMI_EDUCACIONMADRE'\n",
        "]\n",
        "\n",
        "# Normalizar texto eliminando tildes\n",
        "df_train['ESTU_PRGM_ACADEMICO'] = df_train['ESTU_PRGM_ACADEMICO'].apply(lambda x: unidecode(str(x)))\n",
        "df_test['ESTU_PRGM_ACADEMICO'] = df_test['ESTU_PRGM_ACADEMICO'].apply(lambda x: unidecode(str(x)))\n",
        "\n",
        "# Rellenar NaNs con la moda\n",
        "for col in columns_to_convert:\n",
        "    mode_val = df_train[col].mode()[0]\n",
        "    df_train[col] = df_train[col].fillna(mode_val)\n",
        "    df_test[col] = df_test[col].fillna(mode_val)\n",
        "\n",
        "# Codificar features\n",
        "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "df_train[columns_to_convert] = encoder.fit_transform(df_train[columns_to_convert])\n",
        "df_test[columns_to_convert] = encoder.transform(df_test[columns_to_convert])\n",
        "\n",
        "# Codificar target\n",
        "y_train_encoded, target_labels = pd.factorize(df_train[\"RENDIMIENTO_GLOBAL\"])\n",
        "\n",
        "# =============================================================\n",
        "# VARIABLES X e Y\n",
        "# =============================================================\n",
        "\n",
        "X_train = df_train.drop([\"ID\", \"RENDIMIENTO_GLOBAL\"], axis=1)\n",
        "y_train = y_train_encoded\n",
        "X_test = df_test.drop([\"ID\"], axis=1)\n",
        "\n",
        "# =============================================================\n",
        "# GRID SEARCH PARA XGBOOST\n",
        "# =============================================================\n",
        "\n",
        "print(\"\\nüîç Buscando mejores hiperpar√°metros para XGBoost...\")\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [100, 300],\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'max_depth': [3, 5],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "xgb = XGBClassifier(\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric=\"mlogloss\"\n",
        ")\n",
        "\n",
        "xgb_grid = GridSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_grid=xgb_param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgb_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"‚úÖ Mejor configuraci√≥n para XGBoost:\", xgb_grid.best_params_)\n",
        "print(\"‚úÖ Mejor accuracy promedio:\", xgb_grid.best_score_)\n",
        "\n",
        "# =============================================================\n",
        "# GRID SEARCH PARA GradientBoosting\n",
        "# =============================================================\n",
        "\n",
        "print(\"\\nüîç Buscando mejores hiperpar√°metros para GradientBoosting...\")\n",
        "gb_param_grid = {\n",
        "    'n_estimators': [100, 300],\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'max_depth': [3, 5],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "gb_grid = GridSearchCV(\n",
        "    estimator=gb,\n",
        "    param_grid=gb_param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "gb_grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"‚úÖ Mejor configuraci√≥n para GradientBoosting:\", gb_grid.best_params_)\n",
        "print(\"‚úÖ Mejor accuracy promedio:\", gb_grid.best_score_)\n",
        "\n",
        "# =============================================================\n",
        "# ENTRENAMIENTO FINAL CON MEJORES PAR√ÅMETROS\n",
        "# =============================================================\n",
        "\n",
        "# XGBoost entrenado completo\n",
        "best_xgb = XGBClassifier(\n",
        "    **xgb_grid.best_params_,\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric=\"mlogloss\"\n",
        ")\n",
        "best_xgb.fit(X_train, y_train)\n",
        "pred_xgb = best_xgb.predict(X_test)\n",
        "pred_xgb_labels = [target_labels[i] for i in pred_xgb]\n",
        "\n",
        "# GradientBoosting entrenado completo\n",
        "best_gb = GradientBoostingClassifier(\n",
        "    **gb_grid.best_params_,\n",
        "    random_state=42\n",
        ")\n",
        "best_gb.fit(X_train, y_train)\n",
        "pred_gb = best_gb.predict(X_test)\n",
        "pred_gb_labels = [target_labels[i] for i in pred_gb]\n",
        "\n",
        "# =============================================================\n",
        "# CREAR CSV DE SUBMISSION\n",
        "# =============================================================\n",
        "\n",
        "# XGBoost\n",
        "submission_xgb = submission_example.copy()\n",
        "submission_xgb[\"RENDIMIENTO_GLOBAL\"] = pred_xgb_labels\n",
        "submission_xgb.to_csv(\"submission_XGBoost_GridSearch.csv\", index=False)\n",
        "print(\"‚úÖ Archivo creado: submission_XGBoost_GridSearch.csv\")\n",
        "\n",
        "# GradientBoosting\n",
        "submission_gb = submission_example.copy()\n",
        "submission_gb[\"RENDIMIENTO_GLOBAL\"] = pred_gb_labels\n",
        "submission_gb.to_csv(\"submission_GradientBoosting_GridSearch.csv\", index=False)\n",
        "print(\"‚úÖ Archivo creado: submission_GradientBoosting_GridSearch.csv\")\n",
        "\n",
        "print(\"\\nüéâ Proceso completado correctamente.\")\n"
      ]
    }
  ]
}